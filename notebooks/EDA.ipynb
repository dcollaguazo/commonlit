{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "572bf584-0478-4746-84e0-f6e9b15a274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessery libraries\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9152e2-4c65-4aad-84f0-461112657c50",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7a85bf0-cf3e-4ce6-9aa2-92588794ba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "sample_submission.csv                          2021-05-02 22:19:12          108\n",
      "test.csv                                       2021-05-02 22:19:12         6957\n",
      "train.csv                                      2021-05-02 22:19:12      2927187\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "# specifying the zip file name\n",
    "file_name = os.path.join(path,\"commonlitreadabilityprize.zip\")\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "\n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall(path)\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97374c93-8a61-4261-8564-cbe74d9a396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(path,'train.csv')\n",
    "data = pd.read_csv(data_path, usecols=['id','excerpt','target','standard_error'],  index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67bff3f9-10ad-46d6-ac6f-aec7fc6db3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85aa80a4c</th>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b69ac6792</th>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd1000b26</th>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37c1b32fb</th>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "85aa80a4c  All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "b69ac6792  As Roger had predicted, the snow departed as q... -0.580118   \n",
       "dd1000b26  And outside before the palace a great garden w... -1.054013   \n",
       "37c1b32fb  Once upon a time there were Three Bears who li...  0.247197   \n",
       "\n",
       "           standard_error  \n",
       "id                         \n",
       "c12129c31        0.464009  \n",
       "85aa80a4c        0.480805  \n",
       "b69ac6792        0.476676  \n",
       "dd1000b26        0.450007  \n",
       "37c1b32fb        0.510845  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8b0bffe-e974-4dc9-9e21-23a017c1dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All through dinner time, Mrs. Fayre was somewhat silent, her eyes resting on Dolly with a wistful, uncertain expression. She wanted to give the child the pleasure she craved, but she had hard work to bring herself to the point of overcoming her own objections.\\nAt last, however, when the meal was nearly over, she smiled at her little daughter, and said, \"All right, Dolly, you may go.\"\\n\"Oh, mother!\" Dolly cried, overwhelmed with sudden delight. \"Really?\\nOh, I am so glad! Are you sure you\\'re willing?\"\\n\"I\\'ve persuaded myself to be willing, against my will,\" returned Mrs. Fayre, whimsically. \"I confess I just hate to have you go, but I can\\'t bear to deprive you of the pleasure trip. And, as you say, it would also keep Dotty at home, and so, altogether, I think I shall have to give in.\"\\n\"Oh, you angel mother! You blessed lady! How good you are!\" And Dolly flew around the table and gave her mother a hug that nearly suffocated her.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.excerpt.tolist()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a82b6d-5ae8-4461-b2b8-c1d2f7ee8edb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e661968-4945-49d0-b51c-5174cce70efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excerpt length\n",
    "# sentence length\n",
    "# average word length\n",
    "# tf-idf threshold least common words\n",
    "# unique vocab \n",
    "# excerpt similarity for model eval\n",
    "# POS \n",
    "# number of stopwords\n",
    "# entity recognition\n",
    "\n",
    "# compare results after pre-processing text\n",
    "# tf-idf threshold least common words\n",
    "\n",
    "# pre-processing steps:\n",
    "# stemming\n",
    "# lemmatization\n",
    "# punctuation\n",
    "# stopwords\n",
    "# lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcac6971-f8ba-44e0-8a71-9fc6844bbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.pos_ for token in doc]\n",
    "def is_stop(text):\n",
    "    doc = nlp(text)\n",
    "    return sum([token.is_stop for token in doc]) / len(doc)\n",
    "def avg_token_length(text):\n",
    "    doc = nlp(text)\n",
    "    return np.mean([len(token.text) for token in doc if not token.is_stop])\n",
    "def n_token_sents(text):\n",
    "    doc = nlp(text)\n",
    "    return np.mean([len(sent) for sent in doc.sents])\n",
    "def n_sents(text):\n",
    "    doc = nlp(text)\n",
    "    return len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ea2e1e3-1bc4-412f-9e6f-b0e06ccfc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['excerpt_length'] = data.excerpt.apply(lambda x: len(x))\n",
    "# data['n_sents'] = data.excerpt.apply(lambda x: n_sents(x))\n",
    "# data['pos'] = data.excerpt.apply(lambda x: pos(x))\n",
    "# data['n_stop_words'] = data.excerpt.apply(lambda x: is_stop(x))\n",
    "# data['avg_token_length'] = data.excerpt.apply(lambda x: avg_token_length(x))\n",
    "# data['n_token_sents'] = data.excerpt.apply(lambda x: n_token_sents(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a025e-902a-495d-b93a-75b2484e473a",
   "metadata": {},
   "source": [
    "# TFiDF feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accae9ca-bac7-49e2-9ac8-d733e627b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daf7a66d-820b-4ab0-9560-b7675c1d3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data.excerpt.tolist())\n",
    "# pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f909be-d172-4366-b923-d969d0d47839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum tfidf frequency of each term through documents\n",
    "sums = X.sum(axis=1)\n",
    "\n",
    "# visualize supposedly easiest and hardest excerpts based on their tfidf scores\n",
    "print(data['tfidf_doc_score'] = np.array(sums).flatten())\n",
    "print(data.sort_values('tfidf_doc_score').excerpt[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd445c64-eae0-4f14-9eee-e66367de79d0",
   "metadata": {},
   "source": [
    "## Creating a dictionary of rarest terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0f30618d-9ef6-4efa-8010-b2b8c3c0a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums_1 = X.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "temp = []\n",
    "for col, term in enumerate(terms):\n",
    "    temp.append( (term, sums_1[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(temp, columns=['term','rank'])\n",
    "ranking = ranking.sort_values('rank')\n",
    "\n",
    "top_terms = ranking['term'][0:50].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3b1a4-28e2-427c-9d3d-44a8563e9f10",
   "metadata": {},
   "source": [
    "## Counting occurrences of words in dictionary in excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b512d6a7-d50a-40a4-a3d6-1b84c9211340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing excerpts\n",
    "def tokenize(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "data['tokens'] = data.excerpt.apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a7bb61f6-9195-4118-a221-dda77bbf1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count words occurence in excerpt\n",
    "def count(tokens):\n",
    "    dict_word_count = Counter(tokens)\n",
    "    return dict_word_count\n",
    "    \n",
    "data['word_counts'] = data.tokens.apply(lambda x: count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ac09ed4d-f08a-41d5-a15d-7de9d207acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_dict(word_count):\n",
    "    counter=0\n",
    "    for key, value in word_count.items():\n",
    "        if key in top_terms:\n",
    "            counter+=value\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2aa2723d-f245-4319-813c-2fce440e3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['w_dict_count'] = data.word_counts.apply(lambda x: count_word_in_dict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3d1bb-c556-41bf-9cb1-b5f2f1631ffe",
   "metadata": {},
   "source": [
    "# Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1104828d-5632-408c-abb7-902fa2baa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['excerpt'], data['target'], \n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21caa3-3bb9-4713-a715-882eab4872df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
