{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572bf584-0478-4746-84e0-f6e9b15a274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessery libraries\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9152e2-4c65-4aad-84f0-461112657c50",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a85bf0-cf3e-4ce6-9aa2-92588794ba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "sample_submission.csv                          2021-05-02 22:19:12          108\n",
      "test.csv                                       2021-05-02 22:19:12         6957\n",
      "train.csv                                      2021-05-02 22:19:12      2927187\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "# specifying the zip file name\n",
    "file_name = os.path.join(path,\"commonlitreadabilityprize.zip\")\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "\n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall(path)\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97374c93-8a61-4261-8564-cbe74d9a396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(path,'train.csv')\n",
    "data = pd.read_csv(data_path, usecols=['id','excerpt','target','standard_error'],  index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67bff3f9-10ad-46d6-ac6f-aec7fc6db3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85aa80a4c</th>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b69ac6792</th>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd1000b26</th>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37c1b32fb</th>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "85aa80a4c  All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "b69ac6792  As Roger had predicted, the snow departed as q... -0.580118   \n",
       "dd1000b26  And outside before the palace a great garden w... -1.054013   \n",
       "37c1b32fb  Once upon a time there were Three Bears who li...  0.247197   \n",
       "\n",
       "           standard_error  \n",
       "id                         \n",
       "c12129c31        0.464009  \n",
       "85aa80a4c        0.480805  \n",
       "b69ac6792        0.476676  \n",
       "dd1000b26        0.450007  \n",
       "37c1b32fb        0.510845  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b0bffe-e974-4dc9-9e21-23a017c1dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All through dinner time, Mrs. Fayre was somewhat silent, her eyes resting on Dolly with a wistful, uncertain expression. She wanted to give the child the pleasure she craved, but she had hard work to bring herself to the point of overcoming her own objections.\\nAt last, however, when the meal was nearly over, she smiled at her little daughter, and said, \"All right, Dolly, you may go.\"\\n\"Oh, mother!\" Dolly cried, overwhelmed with sudden delight. \"Really?\\nOh, I am so glad! Are you sure you\\'re willing?\"\\n\"I\\'ve persuaded myself to be willing, against my will,\" returned Mrs. Fayre, whimsically. \"I confess I just hate to have you go, but I can\\'t bear to deprive you of the pleasure trip. And, as you say, it would also keep Dotty at home, and so, altogether, I think I shall have to give in.\"\\n\"Oh, you angel mother! You blessed lady! How good you are!\" And Dolly flew around the table and gave her mother a hug that nearly suffocated her.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.excerpt.tolist()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a82b6d-5ae8-4461-b2b8-c1d2f7ee8edb",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e661968-4945-49d0-b51c-5174cce70efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excerpt length\n",
    "# sentence length\n",
    "# average word length\n",
    "# tf-idf threshold least common words\n",
    "# unique vocab \n",
    "# excerpt similarity for model eval\n",
    "# POS \n",
    "# number of stopwords\n",
    "# entity recognition\n",
    "\n",
    "# compare results after pre-processing text\n",
    "# tf-idf threshold least common words\n",
    "\n",
    "# pre-processing steps:\n",
    "# stemming\n",
    "# lemmatization\n",
    "# punctuation\n",
    "# stopwords\n",
    "# lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcac6971-f8ba-44e0-8a71-9fc6844bbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.pos_ for token in doc]\n",
    "def is_stop(text):\n",
    "    doc = nlp(text)\n",
    "    return sum([token.is_stop for token in doc]) / len(doc)\n",
    "def avg_token_length(text):\n",
    "    doc = nlp(text)\n",
    "    return np.mean([len(token.text) for token in doc if not token.is_stop])\n",
    "def n_token_sents(text):\n",
    "    doc = nlp(text)\n",
    "    return np.mean([len(sent) for sent in doc.sents])\n",
    "def n_sents(text):\n",
    "    doc = nlp(text)\n",
    "    return len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ea2e1e3-1bc4-412f-9e6f-b0e06ccfc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['excerpt_length'] = data.excerpt.apply(lambda x: len(x))\n",
    "data['n_sents'] = data.excerpt.apply(lambda x: n_sents(x))\n",
    "data['pos'] = data.excerpt.apply(lambda x: pos(x))\n",
    "data['n_stop_words'] = data.excerpt.apply(lambda x: is_stop(x))\n",
    "data['avg_token_length'] = data.excerpt.apply(lambda x: avg_token_length(x))\n",
    "data['n_token_sents'] = data.excerpt.apply(lambda x: n_token_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accae9ca-bac7-49e2-9ac8-d733e627b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf7a66d-820b-4ab0-9560-b7675c1d3293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>034</th>\n",
       "      <th>04</th>\n",
       "      <th>049</th>\n",
       "      <th>06</th>\n",
       "      <th>...</th>\n",
       "      <th>µv</th>\n",
       "      <th>½d</th>\n",
       "      <th>ædui</th>\n",
       "      <th>ægidus</th>\n",
       "      <th>æmilius</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æolian</th>\n",
       "      <th>æquians</th>\n",
       "      <th>æschylus</th>\n",
       "      <th>ça</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2834 rows × 26833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000th  001   02   03  034   04  049   06  ...   µv   ½d  ædui  \\\n",
       "0     0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "1     0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2     0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "3     0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "4     0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "...   ...  ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "2829  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2830  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2831  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2832  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "2833  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   0.0   \n",
       "\n",
       "      ægidus  æmilius  æneas  æolian  æquians  æschylus   ça  \n",
       "0        0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "1        0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "2        0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "3        0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "4        0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "...      ...      ...    ...     ...      ...       ...  ...  \n",
       "2829     0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "2830     0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "2831     0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "2832     0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "2833     0.0      0.0    0.0     0.0      0.0       0.0  0.0  \n",
       "\n",
       "[2834 rows x 26833 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer= TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data.excerpt.tolist())\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47d91b07-382c-4eb0-b849-8281c3c079b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    term      rank\n",
      "23160                 su  0.049764\n",
      "1113           airplanes  0.049764\n",
      "23830              tease  0.052762\n",
      "14999              mbisa  0.053113\n",
      "16930                oto  0.053113\n",
      "14831              margy  0.053113\n",
      "1723             arbiter  0.058505\n",
      "17112                 p6  0.058505\n",
      "12360                inc  0.058505\n",
      "15255  microarchitecture  0.058505\n",
      "15040          mebibytes  0.058505\n",
      "8843             exocarp  0.058739\n",
      "17621            peppers  0.058739\n",
      "8339            endocarp  0.058739\n",
      "18032               pits  0.058739\n",
      "2214            avocados  0.058739\n",
      "13317            juicier  0.058739\n",
      "6469                ddwg  0.058891\n",
      "15395          minimized  0.058891\n",
      "25060       uncompressed  0.058891\n",
      "5428           connector  0.058891\n",
      "7045        differential  0.058891\n",
      "26126            website  0.059914\n",
      "333                 2005  0.059914\n",
      "1488            animator  0.059914\n",
      "22256            solaris  0.059914\n",
      "10154       futuresplash  0.059914\n",
      "25364            updates  0.059914\n",
      "3551            browsers  0.059914\n",
      "7677            dribbled  0.059919\n",
      "5190           competing  0.059919\n",
      "14401              loser  0.059919\n",
      "13094              iupac  0.060229\n",
      "14238       lithospheric  0.060684\n",
      "19686           recycled  0.060684\n",
      "4244         celebrating  0.062708\n",
      "22879            stiches  0.063006\n",
      "21916               siza  0.063006\n",
      "17232           panicked  0.063006\n",
      "8058                 eii  0.066020\n",
      "14420        loudspeaker  0.067215\n",
      "3444               brier  0.068041\n",
      "18192          plowshare  0.068041\n",
      "10641          goldfinch  0.068041\n",
      "3527           brookside  0.068041\n",
      "16297            nitride  0.068527\n",
      "25278         unreactive  0.068527\n",
      "11120            halides  0.068527\n",
      "11128           halogens  0.068527\n",
      "16761             opaque  0.068527\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = X.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "temp = []\n",
    "for col, term in enumerate(terms):\n",
    "    temp.append((term, sums[0,col] ))\n",
    "\n",
    "ranking = pd.DataFrame(temp, columns=['term','rank'])\n",
    "print(ranking.sort_values('rank', ascending=True).head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46d0ce5b-88bd-4e9a-8487-76d7fa13755e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5b7ad-e25c-4870-8c87-f77b2d806fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1b3d1bb-c556-41bf-9cb1-b5f2f1631ffe",
   "metadata": {},
   "source": [
    "# Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1104828d-5632-408c-abb7-902fa2baa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['excerpt'], data['target'], \n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21caa3-3bb9-4713-a715-882eab4872df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
